  ____________       _____________
 ____    |__( )_________  __/__  /________      __
____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
 _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
[[34m2025-01-27T16:36:01.940-0300[0m] {[34mtask_context_logger.py:[0m63} INFO[0m - Task context logging is enabled[0m
[[34m2025-01-27T16:36:01.943-0300[0m] {[34mexecutor_loader.py:[0m115} INFO[0m - Loaded executor: SequentialExecutor[0m
[[34m2025-01-27T16:36:02.000-0300[0m] {[34mscheduler_job_runner.py:[0m808} INFO[0m - Starting the scheduler[0m
[[34m2025-01-27T16:36:02.002-0300[0m] {[34mscheduler_job_runner.py:[0m815} INFO[0m - Processing each file at most -1 times[0m
[[34m2025-01-27T16:36:02.010-0300[0m] {[34mmanager.py:[0m169} INFO[0m - Launched DagFileProcessorManager with pid: 5032[0m
[[34m2025-01-27T16:36:02.012-0300[0m] {[34mscheduler_job_runner.py:[0m1619} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2025-01-27T16:36:02.016-0300[0m] {[34msettings.py:[0m60} INFO[0m - Configured default timezone UTC[0m
[[34m2025-01-27T16:36:02.036-0300[0m] {[34mscheduler_job_runner.py:[0m1642} INFO[0m - Marked 1 SchedulerJob instances as failed[0m
[2025-01-27T16:36:02.043-0300] {manager.py:392} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[2025-01-27T16:40:03.403-0300] {manager.py:523} INFO - DAG meltano_schedule_test is missing and will be deactivated.
[2025-01-27T16:40:03.409-0300] {manager.py:535} INFO - Deactivated 1 DAGs which are no longer present in file.
[2025-01-27T16:40:03.445-0300] {manager.py:539} INFO - Deleted DAG meltano_schedule_test in serialized_dag table
[[34m2025-01-27T16:41:00.777-0300[0m] {[34mscheduler_job_runner.py:[0m1619} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2025-01-27T16:44:17.177-0300[0m] {[34mscheduler_job_runner.py:[0m1341} INFO[0m - DAG meltano_schedule_test is at (or above) max_active_runs (1 of 1), not creating any more runs[0m
[[34m2025-01-27T16:44:17.264-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: meltano_schedule_test.extract_load scheduled__2025-01-27T18:00:00+00:00 [scheduled]>[0m
[[34m2025-01-27T16:44:17.265-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG meltano_schedule_test has 0/16 running and queued tasks[0m
[[34m2025-01-27T16:44:17.265-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: meltano_schedule_test.extract_load scheduled__2025-01-27T18:00:00+00:00 [scheduled]>[0m
[[34m2025-01-27T16:44:17.269-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task extract_load because previous state change time has not been saved[0m
[[34m2025-01-27T16:44:17.270-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='meltano_schedule_test', task_id='extract_load', run_id='scheduled__2025-01-27T18:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2025-01-27T16:44:17.270-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'meltano_schedule_test', 'extract_load', 'scheduled__2025-01-27T18:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/meltano_dag_generator.py'][0m
[[34m2025-01-27T16:44:17.282-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'meltano_schedule_test', 'extract_load', 'scheduled__2025-01-27T18:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/meltano_dag_generator.py'][0m
[[34m2025-01-27T16:44:19.087-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/orchestrate/airflow/dags/meltano_dag_generator.py[0m
[[34m2025-01-27T16:44:22.112-0300[0m] {[34mmeltano_dag_generator.py:[0m186} INFO[0m - Received meltano v2 style schedule export: {'schedules': {'job': [{'name': 'daily-indicium-load', 'interval': '@hourly', 'cron_interval': '0 * * * *', 'env': {}, 'job': {'name': 'pipeline-csv-and-postgres-to-local-target-postgres', 'tasks': ['tap-postgres target-csv--from-postgres tap-csv--from-csv target-csv--order-details', 'tap-csv target-postgres']}}], 'elt': [{'name': 'schedule_test', 'extractor': 'tap-postgres', 'loader': 'arget-csv--from-postgres', 'transform': 'skip', 'interval': '@hourly', 'start_date': '2025-01-27', 'env': {}, 'cron_interval': '0 * * * *', 'last_successful_run_ended_at': '2025-01-27T02:48:18.773475', 'elt_args': ['tap-postgres', 'arget-csv--from-postgres', '--transform=skip', '--state-id=schedule_test']}]}}[0m
[[34m2025-01-27T16:44:22.112-0300[0m] {[34mmeltano_dag_generator.py:[0m58} INFO[0m - Considering schedule 'schedule_test': {'name': 'schedule_test', 'extractor': 'tap-postgres', 'loader': 'arget-csv--from-postgres', 'transform': 'skip', 'interval': '@hourly', 'start_date': '2025-01-27', 'env': {}, 'cron_interval': '0 * * * *', 'last_successful_run_ended_at': '2025-01-27T02:48:18.773475', 'elt_args': ['tap-postgres', 'arget-csv--from-postgres', '--transform=skip', '--state-id=schedule_test']}[0m
[[34m2025-01-27T16:44:22.118-0300[0m] {[34mmeltano_dag_generator.py:[0m105} INFO[0m - DAG created for schedule 'schedule_test'[0m
[[34m2025-01-27T16:44:22.119-0300[0m] {[34mmeltano_dag_generator.py:[0m146} INFO[0m - Considering task 'tap-postgres target-csv--from-postgres tap-csv--from-csv target-csv--order-details' of schedule 'daily-indicium-load': {'name': 'daily-indicium-load', 'interval': '@hourly', 'cron_interval': '0 * * * *', 'env': {}, 'job': {'name': 'pipeline-csv-and-postgres-to-local-target-postgres', 'tasks': ['tap-postgres target-csv--from-postgres tap-csv--from-csv target-csv--order-details', 'tap-csv target-postgres']}}[0m
[[34m2025-01-27T16:44:22.120-0300[0m] {[34mmeltano_dag_generator.py:[0m168} INFO[0m - Spun off task '<Task(BashOperator): meltano_daily-indicium-load_pipeline-csv-and-postgres-to-local-target-postgres_task0>' of schedule 'daily-indicium-load': {'name': 'daily-indicium-load', 'interval': '@hourly', 'cron_interval': '0 * * * *', 'env': {}, 'job': {'name': 'pipeline-csv-and-postgres-to-local-target-postgres', 'tasks': ['tap-postgres target-csv--from-postgres tap-csv--from-csv target-csv--order-details', 'tap-csv target-postgres']}}[0m
[[34m2025-01-27T16:44:22.120-0300[0m] {[34mmeltano_dag_generator.py:[0m146} INFO[0m - Considering task 'tap-csv target-postgres' of schedule 'daily-indicium-load': {'name': 'daily-indicium-load', 'interval': '@hourly', 'cron_interval': '0 * * * *', 'env': {}, 'job': {'name': 'pipeline-csv-and-postgres-to-local-target-postgres', 'tasks': ['tap-postgres target-csv--from-postgres tap-csv--from-csv target-csv--order-details', 'tap-csv target-postgres']}}[0m
[[34m2025-01-27T16:44:22.121-0300[0m] {[34mmeltano_dag_generator.py:[0m168} INFO[0m - Spun off task '<Task(BashOperator): meltano_daily-indicium-load_pipeline-csv-and-postgres-to-local-target-postgres_task1>' of schedule 'daily-indicium-load': {'name': 'daily-indicium-load', 'interval': '@hourly', 'cron_interval': '0 * * * *', 'env': {}, 'job': {'name': 'pipeline-csv-and-postgres-to-local-target-postgres', 'tasks': ['tap-postgres target-csv--from-postgres tap-csv--from-csv target-csv--order-details', 'tap-csv target-postgres']}}[0m
[[34m2025-01-27T16:44:22.122-0300[0m] {[34mmeltano_dag_generator.py:[0m171} INFO[0m - DAG created for schedule 'daily-indicium-load', task='tap-csv target-postgres'[0m
Changing /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/.meltano/utilities/airflow/logs/dag_id=meltano_schedule_test/run_id=scheduled__2025-01-27T18:00:00+00:00/task_id=extract_load permission to 509
[[34m2025-01-27T16:44:22.363-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: meltano_schedule_test.extract_load scheduled__2025-01-27T18:00:00+00:00 [queued]> on host STEFANO-NOTE.[0m
[[34m2025-01-27T16:44:29.647-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='meltano_schedule_test', task_id='extract_load', run_id='scheduled__2025-01-27T18:00:00+00:00', try_number=1, map_index=-1)[0m
[[34m2025-01-27T16:44:29.659-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=meltano_schedule_test, task_id=extract_load, run_id=scheduled__2025-01-27T18:00:00+00:00, map_index=-1, run_start_date=2025-01-27 19:44:22.456465+00:00, run_end_date=2025-01-27 19:44:28.852724+00:00, run_duration=6.396259, state=up_for_retry, executor_state=success, try_number=1, max_tries=1, job_id=6, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2025-01-27 19:44:17.266579+00:00, queued_by_job_id=5, pid=7569[0m
[[34m2025-01-27T16:45:59.466-0300[0m] {[34mscheduler_job_runner.py:[0m1619} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2025-01-27T16:47:35.536-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: meltano_schedule_test.extract_load scheduled__2025-01-27T18:00:00+00:00 [scheduled]>[0m
[[34m2025-01-27T16:47:35.537-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG meltano_schedule_test has 0/16 running and queued tasks[0m
[[34m2025-01-27T16:47:35.537-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: meltano_schedule_test.extract_load scheduled__2025-01-27T18:00:00+00:00 [scheduled]>[0m
[[34m2025-01-27T16:47:35.539-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='meltano_schedule_test', task_id='extract_load', run_id='scheduled__2025-01-27T18:00:00+00:00', try_number=2, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2025-01-27T16:47:35.540-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'meltano_schedule_test', 'extract_load', 'scheduled__2025-01-27T18:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/meltano_dag_generator.py'][0m
[[34m2025-01-27T16:47:35.551-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'meltano_schedule_test', 'extract_load', 'scheduled__2025-01-27T18:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/meltano_dag_generator.py'][0m
[[34m2025-01-27T16:47:37.392-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/orchestrate/airflow/dags/meltano_dag_generator.py[0m
[[34m2025-01-27T16:47:40.168-0300[0m] {[34mmeltano_dag_generator.py:[0m186} INFO[0m - Received meltano v2 style schedule export: {'schedules': {'job': [{'name': 'daily-indicium-load', 'interval': '@hourly', 'cron_interval': '0 * * * *', 'env': {}, 'job': {'name': 'pipeline-csv-and-postgres-to-local-target-postgres', 'tasks': ['tap-postgres target-csv--from-postgres tap-csv--from-csv target-csv--order-details', 'tap-csv target-postgres']}}], 'elt': [{'name': 'schedule_test', 'extractor': 'tap-postgres', 'loader': 'target-csv--from-postgres', 'transform': 'skip', 'interval': '@hourly', 'start_date': '2025-01-27', 'env': {}, 'cron_interval': '0 * * * *', 'last_successful_run_ended_at': '2025-01-27T02:48:18.773475', 'elt_args': ['tap-postgres', 'target-csv--from-postgres', '--transform=skip', '--state-id=schedule_test']}]}}[0m
[[34m2025-01-27T16:47:40.168-0300[0m] {[34mmeltano_dag_generator.py:[0m58} INFO[0m - Considering schedule 'schedule_test': {'name': 'schedule_test', 'extractor': 'tap-postgres', 'loader': 'target-csv--from-postgres', 'transform': 'skip', 'interval': '@hourly', 'start_date': '2025-01-27', 'env': {}, 'cron_interval': '0 * * * *', 'last_successful_run_ended_at': '2025-01-27T02:48:18.773475', 'elt_args': ['tap-postgres', 'target-csv--from-postgres', '--transform=skip', '--state-id=schedule_test']}[0m
[[34m2025-01-27T16:47:40.172-0300[0m] {[34mmeltano_dag_generator.py:[0m105} INFO[0m - DAG created for schedule 'schedule_test'[0m
[[34m2025-01-27T16:47:40.173-0300[0m] {[34mmeltano_dag_generator.py:[0m146} INFO[0m - Considering task 'tap-postgres target-csv--from-postgres tap-csv--from-csv target-csv--order-details' of schedule 'daily-indicium-load': {'name': 'daily-indicium-load', 'interval': '@hourly', 'cron_interval': '0 * * * *', 'env': {}, 'job': {'name': 'pipeline-csv-and-postgres-to-local-target-postgres', 'tasks': ['tap-postgres target-csv--from-postgres tap-csv--from-csv target-csv--order-details', 'tap-csv target-postgres']}}[0m
[[34m2025-01-27T16:47:40.174-0300[0m] {[34mmeltano_dag_generator.py:[0m168} INFO[0m - Spun off task '<Task(BashOperator): meltano_daily-indicium-load_pipeline-csv-and-postgres-to-local-target-postgres_task0>' of schedule 'daily-indicium-load': {'name': 'daily-indicium-load', 'interval': '@hourly', 'cron_interval': '0 * * * *', 'env': {}, 'job': {'name': 'pipeline-csv-and-postgres-to-local-target-postgres', 'tasks': ['tap-postgres target-csv--from-postgres tap-csv--from-csv target-csv--order-details', 'tap-csv target-postgres']}}[0m
[[34m2025-01-27T16:47:40.174-0300[0m] {[34mmeltano_dag_generator.py:[0m146} INFO[0m - Considering task 'tap-csv target-postgres' of schedule 'daily-indicium-load': {'name': 'daily-indicium-load', 'interval': '@hourly', 'cron_interval': '0 * * * *', 'env': {}, 'job': {'name': 'pipeline-csv-and-postgres-to-local-target-postgres', 'tasks': ['tap-postgres target-csv--from-postgres tap-csv--from-csv target-csv--order-details', 'tap-csv target-postgres']}}[0m
[[34m2025-01-27T16:47:40.175-0300[0m] {[34mmeltano_dag_generator.py:[0m168} INFO[0m - Spun off task '<Task(BashOperator): meltano_daily-indicium-load_pipeline-csv-and-postgres-to-local-target-postgres_task1>' of schedule 'daily-indicium-load': {'name': 'daily-indicium-load', 'interval': '@hourly', 'cron_interval': '0 * * * *', 'env': {}, 'job': {'name': 'pipeline-csv-and-postgres-to-local-target-postgres', 'tasks': ['tap-postgres target-csv--from-postgres tap-csv--from-csv target-csv--order-details', 'tap-csv target-postgres']}}[0m
[[34m2025-01-27T16:47:40.175-0300[0m] {[34mmeltano_dag_generator.py:[0m171} INFO[0m - DAG created for schedule 'daily-indicium-load', task='tap-csv target-postgres'[0m
[[34m2025-01-27T16:47:40.449-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: meltano_schedule_test.extract_load scheduled__2025-01-27T18:00:00+00:00 [queued]> on host STEFANO-NOTE.[0m
[[34m2025-01-27T16:47:52.143-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='meltano_schedule_test', task_id='extract_load', run_id='scheduled__2025-01-27T18:00:00+00:00', try_number=2, map_index=-1)[0m
[[34m2025-01-27T16:47:52.149-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=meltano_schedule_test, task_id=extract_load, run_id=scheduled__2025-01-27T18:00:00+00:00, map_index=-1, run_start_date=2025-01-27 19:47:40.556567+00:00, run_end_date=2025-01-27 19:47:51.566598+00:00, run_duration=11.010031, state=success, executor_state=success, try_number=2, max_tries=2, job_id=7, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2025-01-27 19:47:35.538135+00:00, queued_by_job_id=5, pid=8111[0m
[[34m2025-01-27T16:47:54.320-0300[0m] {[34mdagrun.py:[0m732} INFO[0m - Marking run <DagRun meltano_schedule_test @ 2025-01-27 18:00:00+00:00: scheduled__2025-01-27T18:00:00+00:00, state:running, queued_at: 2025-01-27 19:44:17.165193+00:00. externally triggered: False> successful[0m
[[34m2025-01-27T16:47:54.322-0300[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=meltano_schedule_test, execution_date=2025-01-27 18:00:00+00:00, run_id=scheduled__2025-01-27T18:00:00+00:00, run_start_date=2025-01-27 19:44:17.201436+00:00, run_end_date=2025-01-27 19:47:54.322088+00:00, run_duration=217.120652, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-01-27 18:00:00+00:00, data_interval_end=2025-01-27 19:00:00+00:00, dag_hash=ac090821216f0e00ae72ad1cc8c1cf43[0m
[[34m2025-01-27T16:47:54.327-0300[0m] {[34mscheduler_job_runner.py:[0m1341} INFO[0m - DAG meltano_schedule_test is at (or above) max_active_runs (1 of 1), not creating any more runs[0m
[[34m2025-01-27T16:47:55.425-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: meltano_schedule_test.extract_load manual__2025-01-27T19:46:22.682884+00:00 [scheduled]>[0m
[[34m2025-01-27T16:47:55.425-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG meltano_schedule_test has 0/16 running and queued tasks[0m
[[34m2025-01-27T16:47:55.426-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: meltano_schedule_test.extract_load manual__2025-01-27T19:46:22.682884+00:00 [scheduled]>[0m
[[34m2025-01-27T16:47:55.428-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task extract_load because previous state change time has not been saved[0m
[[34m2025-01-27T16:47:55.429-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='meltano_schedule_test', task_id='extract_load', run_id='manual__2025-01-27T19:46:22.682884+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2025-01-27T16:47:55.429-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'meltano_schedule_test', 'extract_load', 'manual__2025-01-27T19:46:22.682884+00:00', '--local', '--subdir', 'DAGS_FOLDER/meltano_dag_generator.py'][0m
[[34m2025-01-27T16:47:55.443-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'meltano_schedule_test', 'extract_load', 'manual__2025-01-27T19:46:22.682884+00:00', '--local', '--subdir', 'DAGS_FOLDER/meltano_dag_generator.py'][0m
[[34m2025-01-27T16:47:57.023-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/orchestrate/airflow/dags/meltano_dag_generator.py[0m
[[34m2025-01-27T16:47:59.131-0300[0m] {[34mmeltano_dag_generator.py:[0m186} INFO[0m - Received meltano v2 style schedule export: {'schedules': {'job': [{'name': 'daily-indicium-load', 'interval': '@hourly', 'cron_interval': '0 * * * *', 'env': {}, 'job': {'name': 'pipeline-csv-and-postgres-to-local-target-postgres', 'tasks': ['tap-postgres target-csv--from-postgres tap-csv--from-csv target-csv--order-details', 'tap-csv target-postgres']}}], 'elt': [{'name': 'schedule_test', 'extractor': 'tap-postgres', 'loader': 'target-csv--from-postgres', 'transform': 'skip', 'interval': '@hourly', 'start_date': '2025-01-27', 'env': {}, 'cron_interval': '0 * * * *', 'last_successful_run_ended_at': '2025-01-27T19:47:48.806103', 'elt_args': ['tap-postgres', 'target-csv--from-postgres', '--transform=skip', '--state-id=schedule_test']}]}}[0m
[[34m2025-01-27T16:47:59.132-0300[0m] {[34mmeltano_dag_generator.py:[0m58} INFO[0m - Considering schedule 'schedule_test': {'name': 'schedule_test', 'extractor': 'tap-postgres', 'loader': 'target-csv--from-postgres', 'transform': 'skip', 'interval': '@hourly', 'start_date': '2025-01-27', 'env': {}, 'cron_interval': '0 * * * *', 'last_successful_run_ended_at': '2025-01-27T19:47:48.806103', 'elt_args': ['tap-postgres', 'target-csv--from-postgres', '--transform=skip', '--state-id=schedule_test']}[0m
[[34m2025-01-27T16:47:59.135-0300[0m] {[34mmeltano_dag_generator.py:[0m105} INFO[0m - DAG created for schedule 'schedule_test'[0m
[[34m2025-01-27T16:47:59.136-0300[0m] {[34mmeltano_dag_generator.py:[0m146} INFO[0m - Considering task 'tap-postgres target-csv--from-postgres tap-csv--from-csv target-csv--order-details' of schedule 'daily-indicium-load': {'name': 'daily-indicium-load', 'interval': '@hourly', 'cron_interval': '0 * * * *', 'env': {}, 'job': {'name': 'pipeline-csv-and-postgres-to-local-target-postgres', 'tasks': ['tap-postgres target-csv--from-postgres tap-csv--from-csv target-csv--order-details', 'tap-csv target-postgres']}}[0m
[[34m2025-01-27T16:47:59.137-0300[0m] {[34mmeltano_dag_generator.py:[0m168} INFO[0m - Spun off task '<Task(BashOperator): meltano_daily-indicium-load_pipeline-csv-and-postgres-to-local-target-postgres_task0>' of schedule 'daily-indicium-load': {'name': 'daily-indicium-load', 'interval': '@hourly', 'cron_interval': '0 * * * *', 'env': {}, 'job': {'name': 'pipeline-csv-and-postgres-to-local-target-postgres', 'tasks': ['tap-postgres target-csv--from-postgres tap-csv--from-csv target-csv--order-details', 'tap-csv target-postgres']}}[0m
[[34m2025-01-27T16:47:59.137-0300[0m] {[34mmeltano_dag_generator.py:[0m146} INFO[0m - Considering task 'tap-csv target-postgres' of schedule 'daily-indicium-load': {'name': 'daily-indicium-load', 'interval': '@hourly', 'cron_interval': '0 * * * *', 'env': {}, 'job': {'name': 'pipeline-csv-and-postgres-to-local-target-postgres', 'tasks': ['tap-postgres target-csv--from-postgres tap-csv--from-csv target-csv--order-details', 'tap-csv target-postgres']}}[0m
[[34m2025-01-27T16:47:59.138-0300[0m] {[34mmeltano_dag_generator.py:[0m168} INFO[0m - Spun off task '<Task(BashOperator): meltano_daily-indicium-load_pipeline-csv-and-postgres-to-local-target-postgres_task1>' of schedule 'daily-indicium-load': {'name': 'daily-indicium-load', 'interval': '@hourly', 'cron_interval': '0 * * * *', 'env': {}, 'job': {'name': 'pipeline-csv-and-postgres-to-local-target-postgres', 'tasks': ['tap-postgres target-csv--from-postgres tap-csv--from-csv target-csv--order-details', 'tap-csv target-postgres']}}[0m
[[34m2025-01-27T16:47:59.138-0300[0m] {[34mmeltano_dag_generator.py:[0m171} INFO[0m - DAG created for schedule 'daily-indicium-load', task='tap-csv target-postgres'[0m
Changing /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/.meltano/utilities/airflow/logs/dag_id=meltano_schedule_test/run_id=manual__2025-01-27T19:46:22.682884+00:00/task_id=extract_load permission to 509
[[34m2025-01-27T16:47:59.282-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: meltano_schedule_test.extract_load manual__2025-01-27T19:46:22.682884+00:00 [queued]> on host STEFANO-NOTE.[0m
[[34m2025-01-27T16:48:09.091-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='meltano_schedule_test', task_id='extract_load', run_id='manual__2025-01-27T19:46:22.682884+00:00', try_number=1, map_index=-1)[0m
[[34m2025-01-27T16:48:09.096-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=meltano_schedule_test, task_id=extract_load, run_id=manual__2025-01-27T19:46:22.682884+00:00, map_index=-1, run_start_date=2025-01-27 19:47:59.354392+00:00, run_end_date=2025-01-27 19:48:08.546921+00:00, run_duration=9.192529, state=success, executor_state=success, try_number=1, max_tries=1, job_id=8, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2025-01-27 19:47:55.427231+00:00, queued_by_job_id=5, pid=8197[0m
[[34m2025-01-27T16:48:09.186-0300[0m] {[34mdagrun.py:[0m732} INFO[0m - Marking run <DagRun meltano_schedule_test @ 2025-01-27 19:46:22.682884+00:00: manual__2025-01-27T19:46:22.682884+00:00, state:running, queued_at: 2025-01-27 19:46:22.704274+00:00. externally triggered: True> successful[0m
[[34m2025-01-27T16:48:09.186-0300[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=meltano_schedule_test, execution_date=2025-01-27 19:46:22.682884+00:00, run_id=manual__2025-01-27T19:46:22.682884+00:00, run_start_date=2025-01-27 19:47:55.381192+00:00, run_end_date=2025-01-27 19:48:09.186712+00:00, run_duration=13.80552, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-01-27 18:00:00+00:00, data_interval_end=2025-01-27 19:00:00+00:00, dag_hash=ac090821216f0e00ae72ad1cc8c1cf43[0m
[[34m2025-01-27T16:50:59.508-0300[0m] {[34mscheduler_job_runner.py:[0m1619} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2025-01-27T16:55:58.183-0300[0m] {[34mscheduler_job_runner.py:[0m1619} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2025-01-27T17:00:58.251-0300[0m] {[34mscheduler_job_runner.py:[0m1619} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2025-01-27T17:05:56.931-0300[0m] {[34mscheduler_job_runner.py:[0m1619} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2025-01-27T17:09:09.425-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 2 tasks up for execution:
	<TaskInstance: northwin_meltano_pipeline.extract_from_csv_load_csv manual__2025-01-27T20:09:08.885346+00:00 [scheduled]>
	<TaskInstance: northwin_meltano_pipeline.extract_from_postgres_load_csv manual__2025-01-27T20:09:08.885346+00:00 [scheduled]>[0m
[[34m2025-01-27T17:09:09.426-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG northwin_meltano_pipeline has 0/16 running and queued tasks[0m
[[34m2025-01-27T17:09:09.426-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG northwin_meltano_pipeline has 1/16 running and queued tasks[0m
[[34m2025-01-27T17:09:09.427-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: northwin_meltano_pipeline.extract_from_csv_load_csv manual__2025-01-27T20:09:08.885346+00:00 [scheduled]>
	<TaskInstance: northwin_meltano_pipeline.extract_from_postgres_load_csv manual__2025-01-27T20:09:08.885346+00:00 [scheduled]>[0m
[[34m2025-01-27T17:09:09.430-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task extract_from_csv_load_csv because previous state change time has not been saved[0m
[[34m2025-01-27T17:09:09.430-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task extract_from_postgres_load_csv because previous state change time has not been saved[0m
[[34m2025-01-27T17:09:09.431-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='northwin_meltano_pipeline', task_id='extract_from_csv_load_csv', run_id='manual__2025-01-27T20:09:08.885346+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2025-01-27T17:09:09.431-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'northwin_meltano_pipeline', 'extract_from_csv_load_csv', 'manual__2025-01-27T20:09:08.885346+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T17:09:09.432-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='northwin_meltano_pipeline', task_id='extract_from_postgres_load_csv', run_id='manual__2025-01-27T20:09:08.885346+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2025-01-27T17:09:09.433-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'northwin_meltano_pipeline', 'extract_from_postgres_load_csv', 'manual__2025-01-27T20:09:08.885346+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T17:09:09.442-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'northwin_meltano_pipeline', 'extract_from_csv_load_csv', 'manual__2025-01-27T20:09:08.885346+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T17:09:10.922-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/orchestrate/airflow/dags/pipeline_meltano.py[0m
Changing /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/.meltano/utilities/airflow/logs/dag_id=northwin_meltano_pipeline/run_id=manual__2025-01-27T20:09:08.885346+00:00/task_id=extract_from_csv_load_csv permission to 509
[[34m2025-01-27T17:09:11.126-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: northwin_meltano_pipeline.extract_from_csv_load_csv manual__2025-01-27T20:09:08.885346+00:00 [queued]> on host STEFANO-NOTE.[0m
[[34m2025-01-27T17:09:15.913-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'northwin_meltano_pipeline', 'extract_from_postgres_load_csv', 'manual__2025-01-27T20:09:08.885346+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T17:09:17.122-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/orchestrate/airflow/dags/pipeline_meltano.py[0m
Changing /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/.meltano/utilities/airflow/logs/dag_id=northwin_meltano_pipeline/run_id=manual__2025-01-27T20:09:08.885346+00:00/task_id=extract_from_postgres_load_csv permission to 509
[[34m2025-01-27T17:09:17.246-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: northwin_meltano_pipeline.extract_from_postgres_load_csv manual__2025-01-27T20:09:08.885346+00:00 [queued]> on host STEFANO-NOTE.[0m
[[34m2025-01-27T17:09:23.993-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='northwin_meltano_pipeline', task_id='extract_from_csv_load_csv', run_id='manual__2025-01-27T20:09:08.885346+00:00', try_number=1, map_index=-1)[0m
[[34m2025-01-27T17:09:23.994-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='northwin_meltano_pipeline', task_id='extract_from_postgres_load_csv', run_id='manual__2025-01-27T20:09:08.885346+00:00', try_number=1, map_index=-1)[0m
[[34m2025-01-27T17:09:24.020-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=northwin_meltano_pipeline, task_id=extract_from_csv_load_csv, run_id=manual__2025-01-27T20:09:08.885346+00:00, map_index=-1, run_start_date=2025-01-27 20:09:11.205255+00:00, run_end_date=2025-01-27 20:09:15.434349+00:00, run_duration=4.229094, state=up_for_retry, executor_state=success, try_number=1, max_tries=3, job_id=9, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-01-27 20:09:09.428562+00:00, queued_by_job_id=5, pid=12307[0m
[[34m2025-01-27T17:09:24.021-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=northwin_meltano_pipeline, task_id=extract_from_postgres_load_csv, run_id=manual__2025-01-27T20:09:08.885346+00:00, map_index=-1, run_start_date=2025-01-27 20:09:17.330762+00:00, run_end_date=2025-01-27 20:09:23.165458+00:00, run_duration=5.834696, state=success, executor_state=success, try_number=1, max_tries=3, job_id=10, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-01-27 20:09:09.428562+00:00, queued_by_job_id=5, pid=12327[0m
[[34m2025-01-27T17:10:57.042-0300[0m] {[34mscheduler_job_runner.py:[0m1619} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2025-01-27T17:12:15.983-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: northwin_meltano_pipeline.extract_from_csv_load_csv manual__2025-01-27T20:09:08.885346+00:00 [scheduled]>[0m
[[34m2025-01-27T17:12:15.984-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG northwin_meltano_pipeline has 0/16 running and queued tasks[0m
[[34m2025-01-27T17:12:15.984-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: northwin_meltano_pipeline.extract_from_csv_load_csv manual__2025-01-27T20:09:08.885346+00:00 [scheduled]>[0m
[[34m2025-01-27T17:12:15.987-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='northwin_meltano_pipeline', task_id='extract_from_csv_load_csv', run_id='manual__2025-01-27T20:09:08.885346+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2025-01-27T17:12:15.987-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'northwin_meltano_pipeline', 'extract_from_csv_load_csv', 'manual__2025-01-27T20:09:08.885346+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T17:12:15.998-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'northwin_meltano_pipeline', 'extract_from_csv_load_csv', 'manual__2025-01-27T20:09:08.885346+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T17:12:17.763-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/orchestrate/airflow/dags/pipeline_meltano.py[0m
[[34m2025-01-27T17:12:17.968-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: northwin_meltano_pipeline.extract_from_csv_load_csv manual__2025-01-27T20:09:08.885346+00:00 [queued]> on host STEFANO-NOTE.[0m
[[34m2025-01-27T17:12:24.140-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='northwin_meltano_pipeline', task_id='extract_from_csv_load_csv', run_id='manual__2025-01-27T20:09:08.885346+00:00', try_number=2, map_index=-1)[0m
[[34m2025-01-27T17:12:24.145-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=northwin_meltano_pipeline, task_id=extract_from_csv_load_csv, run_id=manual__2025-01-27T20:09:08.885346+00:00, map_index=-1, run_start_date=2025-01-27 20:12:18.048657+00:00, run_end_date=2025-01-27 20:12:23.371483+00:00, run_duration=5.322826, state=up_for_retry, executor_state=success, try_number=2, max_tries=3, job_id=11, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-01-27 20:12:15.985299+00:00, queued_by_job_id=5, pid=12868[0m
[[34m2025-01-27T17:15:24.424-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: northwin_meltano_pipeline.extract_from_csv_load_csv manual__2025-01-27T20:09:08.885346+00:00 [scheduled]>[0m
[[34m2025-01-27T17:15:24.425-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG northwin_meltano_pipeline has 0/16 running and queued tasks[0m
[[34m2025-01-27T17:15:24.426-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: northwin_meltano_pipeline.extract_from_csv_load_csv manual__2025-01-27T20:09:08.885346+00:00 [scheduled]>[0m
[[34m2025-01-27T17:15:24.432-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='northwin_meltano_pipeline', task_id='extract_from_csv_load_csv', run_id='manual__2025-01-27T20:09:08.885346+00:00', try_number=3, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2025-01-27T17:15:24.432-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'northwin_meltano_pipeline', 'extract_from_csv_load_csv', 'manual__2025-01-27T20:09:08.885346+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T17:15:24.447-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'northwin_meltano_pipeline', 'extract_from_csv_load_csv', 'manual__2025-01-27T20:09:08.885346+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T17:15:26.506-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/orchestrate/airflow/dags/pipeline_meltano.py[0m
[[34m2025-01-27T17:15:26.724-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: northwin_meltano_pipeline.extract_from_csv_load_csv manual__2025-01-27T20:09:08.885346+00:00 [queued]> on host STEFANO-NOTE.[0m
[[34m2025-01-27T17:15:33.265-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='northwin_meltano_pipeline', task_id='extract_from_csv_load_csv', run_id='manual__2025-01-27T20:09:08.885346+00:00', try_number=3, map_index=-1)[0m
[[34m2025-01-27T17:15:33.271-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=northwin_meltano_pipeline, task_id=extract_from_csv_load_csv, run_id=manual__2025-01-27T20:09:08.885346+00:00, map_index=-1, run_start_date=2025-01-27 20:15:26.814126+00:00, run_end_date=2025-01-27 20:15:32.663870+00:00, run_duration=5.849744, state=up_for_retry, executor_state=success, try_number=3, max_tries=3, job_id=12, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-01-27 20:15:24.427653+00:00, queued_by_job_id=5, pid=13517[0m
[[34m2025-01-27T17:15:57.100-0300[0m] {[34mscheduler_job_runner.py:[0m1619} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2025-01-27T17:18:16.477-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 2 tasks up for execution:
	<TaskInstance: northwin_meltano_pipeline.extract_from_csv_load_csv manual__2025-01-27T20:18:15.831622+00:00 [scheduled]>
	<TaskInstance: northwin_meltano_pipeline.extract_from_postgres_load_csv manual__2025-01-27T20:18:15.831622+00:00 [scheduled]>[0m
[[34m2025-01-27T17:18:16.477-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG northwin_meltano_pipeline has 0/16 running and queued tasks[0m
[[34m2025-01-27T17:18:16.478-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG northwin_meltano_pipeline has 1/16 running and queued tasks[0m
[[34m2025-01-27T17:18:16.478-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: northwin_meltano_pipeline.extract_from_csv_load_csv manual__2025-01-27T20:18:15.831622+00:00 [scheduled]>
	<TaskInstance: northwin_meltano_pipeline.extract_from_postgres_load_csv manual__2025-01-27T20:18:15.831622+00:00 [scheduled]>[0m
[[34m2025-01-27T17:18:16.480-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task extract_from_csv_load_csv because previous state change time has not been saved[0m
[[34m2025-01-27T17:18:16.480-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task extract_from_postgres_load_csv because previous state change time has not been saved[0m
[[34m2025-01-27T17:18:16.481-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='northwin_meltano_pipeline', task_id='extract_from_csv_load_csv', run_id='manual__2025-01-27T20:18:15.831622+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2025-01-27T17:18:16.481-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'northwin_meltano_pipeline', 'extract_from_csv_load_csv', 'manual__2025-01-27T20:18:15.831622+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T17:18:16.481-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='northwin_meltano_pipeline', task_id='extract_from_postgres_load_csv', run_id='manual__2025-01-27T20:18:15.831622+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2025-01-27T17:18:16.481-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'northwin_meltano_pipeline', 'extract_from_postgres_load_csv', 'manual__2025-01-27T20:18:15.831622+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T17:18:16.492-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'northwin_meltano_pipeline', 'extract_from_csv_load_csv', 'manual__2025-01-27T20:18:15.831622+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T17:18:17.956-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/orchestrate/airflow/dags/pipeline_meltano.py[0m
Changing /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/.meltano/utilities/airflow/logs/dag_id=northwin_meltano_pipeline/run_id=manual__2025-01-27T20:18:15.831622+00:00/task_id=extract_from_csv_load_csv permission to 509
[[34m2025-01-27T17:18:18.140-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: northwin_meltano_pipeline.extract_from_csv_load_csv manual__2025-01-27T20:18:15.831622+00:00 [queued]> on host STEFANO-NOTE.[0m
[[34m2025-01-27T17:18:23.878-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'northwin_meltano_pipeline', 'extract_from_postgres_load_csv', 'manual__2025-01-27T20:18:15.831622+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T17:18:25.697-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/orchestrate/airflow/dags/pipeline_meltano.py[0m
Changing /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/.meltano/utilities/airflow/logs/dag_id=northwin_meltano_pipeline/run_id=manual__2025-01-27T20:18:15.831622+00:00/task_id=extract_from_postgres_load_csv permission to 509
[[34m2025-01-27T17:18:25.888-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: northwin_meltano_pipeline.extract_from_postgres_load_csv manual__2025-01-27T20:18:15.831622+00:00 [queued]> on host STEFANO-NOTE.[0m
[[34m2025-01-27T17:18:32.869-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='northwin_meltano_pipeline', task_id='extract_from_csv_load_csv', run_id='manual__2025-01-27T20:18:15.831622+00:00', try_number=1, map_index=-1)[0m
[[34m2025-01-27T17:18:32.870-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='northwin_meltano_pipeline', task_id='extract_from_postgres_load_csv', run_id='manual__2025-01-27T20:18:15.831622+00:00', try_number=1, map_index=-1)[0m
[[34m2025-01-27T17:18:32.879-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=northwin_meltano_pipeline, task_id=extract_from_csv_load_csv, run_id=manual__2025-01-27T20:18:15.831622+00:00, map_index=-1, run_start_date=2025-01-27 20:18:18.196934+00:00, run_end_date=2025-01-27 20:18:23.294921+00:00, run_duration=5.097987, state=success, executor_state=success, try_number=1, max_tries=3, job_id=13, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-01-27 20:18:16.479093+00:00, queued_by_job_id=5, pid=14104[0m
[[34m2025-01-27T17:18:32.880-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=northwin_meltano_pipeline, task_id=extract_from_postgres_load_csv, run_id=manual__2025-01-27T20:18:15.831622+00:00, map_index=-1, run_start_date=2025-01-27 20:18:26.009665+00:00, run_end_date=2025-01-27 20:18:32.290531+00:00, run_duration=6.280866, state=success, executor_state=success, try_number=1, max_tries=3, job_id=14, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-01-27 20:18:16.479093+00:00, queued_by_job_id=5, pid=14146[0m
[[34m2025-01-27T17:18:35.821-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 2 tasks up for execution:
	<TaskInstance: northwin_meltano_pipeline.extract_from_csv_load_csv manual__2025-01-27T20:09:08.885346+00:00 [scheduled]>
	<TaskInstance: northwin_meltano_pipeline.extract_from_csv_load_postgres manual__2025-01-27T20:18:15.831622+00:00 [scheduled]>[0m
[[34m2025-01-27T17:18:35.822-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG northwin_meltano_pipeline has 0/16 running and queued tasks[0m
[[34m2025-01-27T17:18:35.822-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG northwin_meltano_pipeline has 1/16 running and queued tasks[0m
[[34m2025-01-27T17:18:35.822-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: northwin_meltano_pipeline.extract_from_csv_load_csv manual__2025-01-27T20:09:08.885346+00:00 [scheduled]>
	<TaskInstance: northwin_meltano_pipeline.extract_from_csv_load_postgres manual__2025-01-27T20:18:15.831622+00:00 [scheduled]>[0m
[[34m2025-01-27T17:18:35.826-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task extract_from_csv_load_postgres because previous state change time has not been saved[0m
[[34m2025-01-27T17:18:35.827-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='northwin_meltano_pipeline', task_id='extract_from_csv_load_csv', run_id='manual__2025-01-27T20:09:08.885346+00:00', try_number=4, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2025-01-27T17:18:35.827-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'northwin_meltano_pipeline', 'extract_from_csv_load_csv', 'manual__2025-01-27T20:09:08.885346+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T17:18:35.828-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='northwin_meltano_pipeline', task_id='extract_from_csv_load_postgres', run_id='manual__2025-01-27T20:18:15.831622+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2025-01-27T17:18:35.828-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'northwin_meltano_pipeline', 'extract_from_csv_load_postgres', 'manual__2025-01-27T20:18:15.831622+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T17:18:35.838-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'northwin_meltano_pipeline', 'extract_from_csv_load_csv', 'manual__2025-01-27T20:09:08.885346+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T17:18:37.633-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/orchestrate/airflow/dags/pipeline_meltano.py[0m
[[34m2025-01-27T17:18:37.845-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: northwin_meltano_pipeline.extract_from_csv_load_csv manual__2025-01-27T20:09:08.885346+00:00 [queued]> on host STEFANO-NOTE.[0m
[[34m2025-01-27T17:18:43.466-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'northwin_meltano_pipeline', 'extract_from_csv_load_postgres', 'manual__2025-01-27T20:18:15.831622+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T17:18:45.346-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/orchestrate/airflow/dags/pipeline_meltano.py[0m
Changing /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/.meltano/utilities/airflow/logs/dag_id=northwin_meltano_pipeline/run_id=manual__2025-01-27T20:18:15.831622+00:00/task_id=extract_from_csv_load_postgres permission to 509
[[34m2025-01-27T17:18:45.558-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: northwin_meltano_pipeline.extract_from_csv_load_postgres manual__2025-01-27T20:18:15.831622+00:00 [queued]> on host STEFANO-NOTE.[0m
[[34m2025-01-27T17:18:55.552-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='northwin_meltano_pipeline', task_id='extract_from_csv_load_csv', run_id='manual__2025-01-27T20:09:08.885346+00:00', try_number=4, map_index=-1)[0m
[[34m2025-01-27T17:18:55.553-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='northwin_meltano_pipeline', task_id='extract_from_csv_load_postgres', run_id='manual__2025-01-27T20:18:15.831622+00:00', try_number=1, map_index=-1)[0m
[[34m2025-01-27T17:18:55.564-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=northwin_meltano_pipeline, task_id=extract_from_csv_load_postgres, run_id=manual__2025-01-27T20:18:15.831622+00:00, map_index=-1, run_start_date=2025-01-27 20:18:45.653010+00:00, run_end_date=2025-01-27 20:18:54.981488+00:00, run_duration=9.328478, state=success, executor_state=success, try_number=1, max_tries=3, job_id=16, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2025-01-27 20:18:35.823720+00:00, queued_by_job_id=5, pid=14231[0m
[[34m2025-01-27T17:18:55.565-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=northwin_meltano_pipeline, task_id=extract_from_csv_load_csv, run_id=manual__2025-01-27T20:09:08.885346+00:00, map_index=-1, run_start_date=2025-01-27 20:18:37.931367+00:00, run_end_date=2025-01-27 20:18:42.903737+00:00, run_duration=4.97237, state=success, executor_state=success, try_number=4, max_tries=3, job_id=15, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-01-27 20:18:35.823720+00:00, queued_by_job_id=5, pid=14192[0m
[[34m2025-01-27T17:18:55.869-0300[0m] {[34mdagrun.py:[0m732} INFO[0m - Marking run <DagRun northwin_meltano_pipeline @ 2025-01-27 20:18:15.831622+00:00: manual__2025-01-27T20:18:15.831622+00:00, state:running, queued_at: 2025-01-27 20:18:15.851137+00:00. externally triggered: True> successful[0m
[[34m2025-01-27T17:18:55.870-0300[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=northwin_meltano_pipeline, execution_date=2025-01-27 20:18:15.831622+00:00, run_id=manual__2025-01-27T20:18:15.831622+00:00, run_start_date=2025-01-27 20:18:16.431441+00:00, run_end_date=2025-01-27 20:18:55.870199+00:00, run_duration=39.438758, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-01-26 00:00:00+00:00, data_interval_end=2025-01-27 00:00:00+00:00, dag_hash=b2225949f66fd87f5b12f0045741e646[0m
[[34m2025-01-27T17:18:55.915-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: northwin_meltano_pipeline.extract_from_csv_load_postgres manual__2025-01-27T20:09:08.885346+00:00 [scheduled]>[0m
[[34m2025-01-27T17:18:55.915-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG northwin_meltano_pipeline has 0/16 running and queued tasks[0m
[[34m2025-01-27T17:18:55.915-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: northwin_meltano_pipeline.extract_from_csv_load_postgres manual__2025-01-27T20:09:08.885346+00:00 [scheduled]>[0m
[[34m2025-01-27T17:18:55.917-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task extract_from_csv_load_postgres because previous state change time has not been saved[0m
[[34m2025-01-27T17:18:55.918-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='northwin_meltano_pipeline', task_id='extract_from_csv_load_postgres', run_id='manual__2025-01-27T20:09:08.885346+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2025-01-27T17:18:55.918-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'northwin_meltano_pipeline', 'extract_from_csv_load_postgres', 'manual__2025-01-27T20:09:08.885346+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T17:18:55.930-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'northwin_meltano_pipeline', 'extract_from_csv_load_postgres', 'manual__2025-01-27T20:09:08.885346+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T17:18:57.811-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/orchestrate/airflow/dags/pipeline_meltano.py[0m
Changing /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/.meltano/utilities/airflow/logs/dag_id=northwin_meltano_pipeline/run_id=manual__2025-01-27T20:09:08.885346+00:00/task_id=extract_from_csv_load_postgres permission to 509
[[34m2025-01-27T17:18:58.001-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: northwin_meltano_pipeline.extract_from_csv_load_postgres manual__2025-01-27T20:09:08.885346+00:00 [queued]> on host STEFANO-NOTE.[0m
[[34m2025-01-27T17:19:06.821-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='northwin_meltano_pipeline', task_id='extract_from_csv_load_postgres', run_id='manual__2025-01-27T20:09:08.885346+00:00', try_number=1, map_index=-1)[0m
[[34m2025-01-27T17:19:06.825-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=northwin_meltano_pipeline, task_id=extract_from_csv_load_postgres, run_id=manual__2025-01-27T20:09:08.885346+00:00, map_index=-1, run_start_date=2025-01-27 20:18:58.090715+00:00, run_end_date=2025-01-27 20:19:06.311649+00:00, run_duration=8.220934, state=success, executor_state=success, try_number=1, max_tries=3, job_id=17, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2025-01-27 20:18:55.916356+00:00, queued_by_job_id=5, pid=14303[0m
[[34m2025-01-27T17:19:55.647-0300[0m] {[34mdagrun.py:[0m732} INFO[0m - Marking run <DagRun northwin_meltano_pipeline @ 2025-01-27 20:09:08.885346+00:00: manual__2025-01-27T20:09:08.885346+00:00, state:running, queued_at: 2025-01-27 20:09:08.909351+00:00. externally triggered: True> successful[0m
[[34m2025-01-27T17:19:55.648-0300[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=northwin_meltano_pipeline, execution_date=2025-01-27 20:09:08.885346+00:00, run_id=manual__2025-01-27T20:09:08.885346+00:00, run_start_date=2025-01-27 20:09:09.382546+00:00, run_end_date=2025-01-27 20:19:55.647916+00:00, run_duration=646.26537, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-01-26 00:00:00+00:00, data_interval_end=2025-01-27 00:00:00+00:00, dag_hash=b2225949f66fd87f5b12f0045741e646[0m
[[34m2025-01-27T17:20:55.749-0300[0m] {[34mscheduler_job_runner.py:[0m1619} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2025-01-27T17:25:55.772-0300[0m] {[34mscheduler_job_runner.py:[0m1619} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2025-01-27T17:30:54.408-0300[0m] {[34mscheduler_job_runner.py:[0m1619} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2025-01-27T17:35:54.457-0300[0m] {[34mscheduler_job_runner.py:[0m1619} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2025-01-27T17:38:38.550-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 2 tasks up for execution:
	<TaskInstance: northwin_meltano_pipeline.extract_from_csv_load_csv manual__2025-01-27T20:38:37.987846+00:00 [scheduled]>
	<TaskInstance: northwin_meltano_pipeline.extract_from_postgres_load_csv manual__2025-01-27T20:38:37.987846+00:00 [scheduled]>[0m
[[34m2025-01-27T17:38:38.550-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG northwin_meltano_pipeline has 0/16 running and queued tasks[0m
[[34m2025-01-27T17:38:38.551-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG northwin_meltano_pipeline has 1/16 running and queued tasks[0m
[[34m2025-01-27T17:38:38.551-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: northwin_meltano_pipeline.extract_from_csv_load_csv manual__2025-01-27T20:38:37.987846+00:00 [scheduled]>
	<TaskInstance: northwin_meltano_pipeline.extract_from_postgres_load_csv manual__2025-01-27T20:38:37.987846+00:00 [scheduled]>[0m
[[34m2025-01-27T17:38:38.553-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task extract_from_csv_load_csv because previous state change time has not been saved[0m
[[34m2025-01-27T17:38:38.554-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task extract_from_postgres_load_csv because previous state change time has not been saved[0m
[[34m2025-01-27T17:38:38.555-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='northwin_meltano_pipeline', task_id='extract_from_csv_load_csv', run_id='manual__2025-01-27T20:38:37.987846+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2025-01-27T17:38:38.555-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'northwin_meltano_pipeline', 'extract_from_csv_load_csv', 'manual__2025-01-27T20:38:37.987846+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T17:38:38.556-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='northwin_meltano_pipeline', task_id='extract_from_postgres_load_csv', run_id='manual__2025-01-27T20:38:37.987846+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2025-01-27T17:38:38.556-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'northwin_meltano_pipeline', 'extract_from_postgres_load_csv', 'manual__2025-01-27T20:38:37.987846+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T17:38:38.568-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'northwin_meltano_pipeline', 'extract_from_csv_load_csv', 'manual__2025-01-27T20:38:37.987846+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T17:38:40.573-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/orchestrate/airflow/dags/pipeline_meltano.py[0m
Changing /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/.meltano/utilities/airflow/logs/dag_id=northwin_meltano_pipeline/run_id=manual__2025-01-27T20:38:37.987846+00:00/task_id=extract_from_csv_load_csv permission to 509
[[34m2025-01-27T17:38:40.796-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: northwin_meltano_pipeline.extract_from_csv_load_csv manual__2025-01-27T20:38:37.987846+00:00 [queued]> on host STEFANO-NOTE.[0m
[[34m2025-01-27T17:38:46.993-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'northwin_meltano_pipeline', 'extract_from_postgres_load_csv', 'manual__2025-01-27T20:38:37.987846+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T17:38:48.786-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/orchestrate/airflow/dags/pipeline_meltano.py[0m
Changing /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/.meltano/utilities/airflow/logs/dag_id=northwin_meltano_pipeline/run_id=manual__2025-01-27T20:38:37.987846+00:00/task_id=extract_from_postgres_load_csv permission to 509
[[34m2025-01-27T17:38:49.010-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: northwin_meltano_pipeline.extract_from_postgres_load_csv manual__2025-01-27T20:38:37.987846+00:00 [queued]> on host STEFANO-NOTE.[0m
[[34m2025-01-27T17:38:56.781-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='northwin_meltano_pipeline', task_id='extract_from_csv_load_csv', run_id='manual__2025-01-27T20:38:37.987846+00:00', try_number=1, map_index=-1)[0m
[[34m2025-01-27T17:38:56.781-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='northwin_meltano_pipeline', task_id='extract_from_postgres_load_csv', run_id='manual__2025-01-27T20:38:37.987846+00:00', try_number=1, map_index=-1)[0m
[[34m2025-01-27T17:38:56.788-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=northwin_meltano_pipeline, task_id=extract_from_csv_load_csv, run_id=manual__2025-01-27T20:38:37.987846+00:00, map_index=-1, run_start_date=2025-01-27 20:38:40.914094+00:00, run_end_date=2025-01-27 20:38:46.434283+00:00, run_duration=5.520189, state=up_for_retry, executor_state=success, try_number=1, max_tries=3, job_id=18, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-01-27 20:38:38.552066+00:00, queued_by_job_id=5, pid=18946[0m
[[34m2025-01-27T17:38:56.789-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=northwin_meltano_pipeline, task_id=extract_from_postgres_load_csv, run_id=manual__2025-01-27T20:38:37.987846+00:00, map_index=-1, run_start_date=2025-01-27 20:38:49.105811+00:00, run_end_date=2025-01-27 20:38:56.179890+00:00, run_duration=7.074079, state=up_for_retry, executor_state=success, try_number=1, max_tries=3, job_id=19, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-01-27 20:38:38.552066+00:00, queued_by_job_id=5, pid=18984[0m
[[34m2025-01-27T17:39:26.950-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: northwin_meltano_pipeline.extract_from_csv_load_csv manual__2025-01-27T20:38:37.987846+00:00 [scheduled]>[0m
[[34m2025-01-27T17:39:26.950-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG northwin_meltano_pipeline has 0/16 running and queued tasks[0m
[[34m2025-01-27T17:39:26.950-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: northwin_meltano_pipeline.extract_from_csv_load_csv manual__2025-01-27T20:38:37.987846+00:00 [scheduled]>[0m
[[34m2025-01-27T17:39:26.952-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='northwin_meltano_pipeline', task_id='extract_from_csv_load_csv', run_id='manual__2025-01-27T20:38:37.987846+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2025-01-27T17:39:26.952-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'northwin_meltano_pipeline', 'extract_from_csv_load_csv', 'manual__2025-01-27T20:38:37.987846+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T17:39:26.961-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'northwin_meltano_pipeline', 'extract_from_csv_load_csv', 'manual__2025-01-27T20:38:37.987846+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T17:39:28.771-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/orchestrate/airflow/dags/pipeline_meltano.py[0m
[[34m2025-01-27T17:39:28.992-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: northwin_meltano_pipeline.extract_from_csv_load_csv manual__2025-01-27T20:38:37.987846+00:00 [queued]> on host STEFANO-NOTE.[0m
[[34m2025-01-27T17:39:34.049-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='northwin_meltano_pipeline', task_id='extract_from_csv_load_csv', run_id='manual__2025-01-27T20:38:37.987846+00:00', try_number=2, map_index=-1)[0m
[[34m2025-01-27T17:39:34.055-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=northwin_meltano_pipeline, task_id=extract_from_csv_load_csv, run_id=manual__2025-01-27T20:38:37.987846+00:00, map_index=-1, run_start_date=2025-01-27 20:39:29.086114+00:00, run_end_date=2025-01-27 20:39:33.514374+00:00, run_duration=4.42826, state=up_for_retry, executor_state=success, try_number=2, max_tries=4, job_id=20, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-01-27 20:39:26.951252+00:00, queued_by_job_id=5, pid=19082[0m
[[34m2025-01-27T17:39:34.378-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: northwin_meltano_pipeline.extract_from_postgres_load_csv manual__2025-01-27T20:38:37.987846+00:00 [scheduled]>[0m
[[34m2025-01-27T17:39:34.379-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG northwin_meltano_pipeline has 0/16 running and queued tasks[0m
[[34m2025-01-27T17:39:34.379-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: northwin_meltano_pipeline.extract_from_postgres_load_csv manual__2025-01-27T20:38:37.987846+00:00 [scheduled]>[0m
[[34m2025-01-27T17:39:34.381-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='northwin_meltano_pipeline', task_id='extract_from_postgres_load_csv', run_id='manual__2025-01-27T20:38:37.987846+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2025-01-27T17:39:34.381-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'northwin_meltano_pipeline', 'extract_from_postgres_load_csv', 'manual__2025-01-27T20:38:37.987846+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T17:39:34.392-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'northwin_meltano_pipeline', 'extract_from_postgres_load_csv', 'manual__2025-01-27T20:38:37.987846+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T17:39:35.904-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/orchestrate/airflow/dags/pipeline_meltano.py[0m
[[34m2025-01-27T17:39:36.070-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: northwin_meltano_pipeline.extract_from_postgres_load_csv manual__2025-01-27T20:38:37.987846+00:00 [queued]> on host STEFANO-NOTE.[0m
[[34m2025-01-27T17:39:43.137-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='northwin_meltano_pipeline', task_id='extract_from_postgres_load_csv', run_id='manual__2025-01-27T20:38:37.987846+00:00', try_number=2, map_index=-1)[0m
[[34m2025-01-27T17:39:43.144-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=northwin_meltano_pipeline, task_id=extract_from_postgres_load_csv, run_id=manual__2025-01-27T20:38:37.987846+00:00, map_index=-1, run_start_date=2025-01-27 20:39:36.129478+00:00, run_end_date=2025-01-27 20:39:42.586371+00:00, run_duration=6.456893, state=up_for_retry, executor_state=success, try_number=2, max_tries=4, job_id=21, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-01-27 20:39:34.379840+00:00, queued_by_job_id=5, pid=19120[0m
[[34m2025-01-27T17:40:54.527-0300[0m] {[34mscheduler_job_runner.py:[0m1619} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2025-01-27T17:41:17.324-0300[0m] {[34mdagrun.py:[0m711} ERROR[0m - Marking run <DagRun northwin_meltano_pipeline @ 2025-01-27 20:38:37.987846+00:00: manual__2025-01-27T20:38:37.987846+00:00, state:running, queued_at: 2025-01-27 20:38:38.008061+00:00. externally triggered: True> failed[0m
[[34m2025-01-27T17:41:17.326-0300[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=northwin_meltano_pipeline, execution_date=2025-01-27 20:38:37.987846+00:00, run_id=manual__2025-01-27T20:38:37.987846+00:00, run_start_date=2025-01-27 20:38:38.489567+00:00, run_end_date=2025-01-27 20:41:17.325958+00:00, run_duration=158.836391, state=failed, external_trigger=True, run_type=manual, data_interval_start=2025-01-26 00:00:00+00:00, data_interval_end=2025-01-27 00:00:00+00:00, dag_hash=b2225949f66fd87f5b12f0045741e646[0m
[[34m2025-01-27T17:41:26.862-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 2 tasks up for execution:
	<TaskInstance: northwin_meltano_pipeline.extract_from_csv_load_csv manual__2025-01-27T20:41:25.608518+00:00 [scheduled]>
	<TaskInstance: northwin_meltano_pipeline.extract_from_postgres_load_csv manual__2025-01-27T20:41:25.608518+00:00 [scheduled]>[0m
[[34m2025-01-27T17:41:26.863-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG northwin_meltano_pipeline has 0/16 running and queued tasks[0m
[[34m2025-01-27T17:41:26.863-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG northwin_meltano_pipeline has 1/16 running and queued tasks[0m
[[34m2025-01-27T17:41:26.863-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: northwin_meltano_pipeline.extract_from_csv_load_csv manual__2025-01-27T20:41:25.608518+00:00 [scheduled]>
	<TaskInstance: northwin_meltano_pipeline.extract_from_postgres_load_csv manual__2025-01-27T20:41:25.608518+00:00 [scheduled]>[0m
[[34m2025-01-27T17:41:26.866-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task extract_from_csv_load_csv because previous state change time has not been saved[0m
[[34m2025-01-27T17:41:26.866-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task extract_from_postgres_load_csv because previous state change time has not been saved[0m
[[34m2025-01-27T17:41:26.867-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='northwin_meltano_pipeline', task_id='extract_from_csv_load_csv', run_id='manual__2025-01-27T20:41:25.608518+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2025-01-27T17:41:26.867-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'northwin_meltano_pipeline', 'extract_from_csv_load_csv', 'manual__2025-01-27T20:41:25.608518+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T17:41:26.868-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='northwin_meltano_pipeline', task_id='extract_from_postgres_load_csv', run_id='manual__2025-01-27T20:41:25.608518+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2025-01-27T17:41:26.868-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'northwin_meltano_pipeline', 'extract_from_postgres_load_csv', 'manual__2025-01-27T20:41:25.608518+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T17:41:26.877-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'northwin_meltano_pipeline', 'extract_from_csv_load_csv', 'manual__2025-01-27T20:41:25.608518+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T17:41:28.349-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/orchestrate/airflow/dags/pipeline_meltano.py[0m
Changing /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/.meltano/utilities/airflow/logs/dag_id=northwin_meltano_pipeline/run_id=manual__2025-01-27T20:41:25.608518+00:00/task_id=extract_from_csv_load_csv permission to 509
[[34m2025-01-27T17:41:28.497-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: northwin_meltano_pipeline.extract_from_csv_load_csv manual__2025-01-27T20:41:25.608518+00:00 [queued]> on host STEFANO-NOTE.[0m
[[34m2025-01-27T17:41:33.792-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'northwin_meltano_pipeline', 'extract_from_postgres_load_csv', 'manual__2025-01-27T20:41:25.608518+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T17:41:35.593-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/orchestrate/airflow/dags/pipeline_meltano.py[0m
Changing /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/.meltano/utilities/airflow/logs/dag_id=northwin_meltano_pipeline/run_id=manual__2025-01-27T20:41:25.608518+00:00/task_id=extract_from_postgres_load_csv permission to 509
[[34m2025-01-27T17:41:35.784-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: northwin_meltano_pipeline.extract_from_postgres_load_csv manual__2025-01-27T20:41:25.608518+00:00 [queued]> on host STEFANO-NOTE.[0m
[[34m2025-01-27T17:41:42.662-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='northwin_meltano_pipeline', task_id='extract_from_csv_load_csv', run_id='manual__2025-01-27T20:41:25.608518+00:00', try_number=1, map_index=-1)[0m
[[34m2025-01-27T17:41:42.663-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='northwin_meltano_pipeline', task_id='extract_from_postgres_load_csv', run_id='manual__2025-01-27T20:41:25.608518+00:00', try_number=1, map_index=-1)[0m
[[34m2025-01-27T17:41:42.667-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=northwin_meltano_pipeline, task_id=extract_from_csv_load_csv, run_id=manual__2025-01-27T20:41:25.608518+00:00, map_index=-1, run_start_date=2025-01-27 20:41:28.583115+00:00, run_end_date=2025-01-27 20:41:33.236142+00:00, run_duration=4.653027, state=success, executor_state=success, try_number=1, max_tries=3, job_id=22, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-01-27 20:41:26.864794+00:00, queued_by_job_id=5, pid=19461[0m
[[34m2025-01-27T17:41:42.668-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=northwin_meltano_pipeline, task_id=extract_from_postgres_load_csv, run_id=manual__2025-01-27T20:41:25.608518+00:00, map_index=-1, run_start_date=2025-01-27 20:41:35.876014+00:00, run_end_date=2025-01-27 20:41:42.130107+00:00, run_duration=6.254093, state=success, executor_state=success, try_number=1, max_tries=3, job_id=23, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-01-27 20:41:26.864794+00:00, queued_by_job_id=5, pid=19492[0m
[[34m2025-01-27T17:41:42.993-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: northwin_meltano_pipeline.extract_from_csv_load_postgres manual__2025-01-27T20:41:25.608518+00:00 [scheduled]>[0m
[[34m2025-01-27T17:41:42.993-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG northwin_meltano_pipeline has 0/16 running and queued tasks[0m
[[34m2025-01-27T17:41:42.994-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: northwin_meltano_pipeline.extract_from_csv_load_postgres manual__2025-01-27T20:41:25.608518+00:00 [scheduled]>[0m
[[34m2025-01-27T17:41:42.996-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task extract_from_csv_load_postgres because previous state change time has not been saved[0m
[[34m2025-01-27T17:41:42.996-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='northwin_meltano_pipeline', task_id='extract_from_csv_load_postgres', run_id='manual__2025-01-27T20:41:25.608518+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2025-01-27T17:41:42.997-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'northwin_meltano_pipeline', 'extract_from_csv_load_postgres', 'manual__2025-01-27T20:41:25.608518+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T17:41:43.008-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'northwin_meltano_pipeline', 'extract_from_csv_load_postgres', 'manual__2025-01-27T20:41:25.608518+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T17:41:44.784-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/orchestrate/airflow/dags/pipeline_meltano.py[0m
Changing /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/.meltano/utilities/airflow/logs/dag_id=northwin_meltano_pipeline/run_id=manual__2025-01-27T20:41:25.608518+00:00/task_id=extract_from_csv_load_postgres permission to 509
[[34m2025-01-27T17:41:44.974-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: northwin_meltano_pipeline.extract_from_csv_load_postgres manual__2025-01-27T20:41:25.608518+00:00 [queued]> on host STEFANO-NOTE.[0m
[[34m2025-01-27T17:41:54.093-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='northwin_meltano_pipeline', task_id='extract_from_csv_load_postgres', run_id='manual__2025-01-27T20:41:25.608518+00:00', try_number=1, map_index=-1)[0m
[[34m2025-01-27T17:41:54.099-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=northwin_meltano_pipeline, task_id=extract_from_csv_load_postgres, run_id=manual__2025-01-27T20:41:25.608518+00:00, map_index=-1, run_start_date=2025-01-27 20:41:45.088823+00:00, run_end_date=2025-01-27 20:41:53.492075+00:00, run_duration=8.403252, state=success, executor_state=success, try_number=1, max_tries=3, job_id=24, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2025-01-27 20:41:42.995053+00:00, queued_by_job_id=5, pid=19537[0m
[[34m2025-01-27T17:41:54.160-0300[0m] {[34mdagrun.py:[0m732} INFO[0m - Marking run <DagRun northwin_meltano_pipeline @ 2025-01-27 20:41:25.608518+00:00: manual__2025-01-27T20:41:25.608518+00:00, state:running, queued_at: 2025-01-27 20:41:25.619597+00:00. externally triggered: True> successful[0m
[[34m2025-01-27T17:41:54.160-0300[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=northwin_meltano_pipeline, execution_date=2025-01-27 20:41:25.608518+00:00, run_id=manual__2025-01-27T20:41:25.608518+00:00, run_start_date=2025-01-27 20:41:26.738681+00:00, run_end_date=2025-01-27 20:41:54.160746+00:00, run_duration=27.422065, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-01-26 00:00:00+00:00, data_interval_end=2025-01-27 00:00:00+00:00, dag_hash=b2225949f66fd87f5b12f0045741e646[0m
[[34m2025-01-27T17:45:53.122-0300[0m] {[34mscheduler_job_runner.py:[0m1619} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2025-01-27T20:41:07.850-0300[0m] {[34mscheduler_job_runner.py:[0m1619} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2025-01-27T20:45:10.466-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 2 tasks up for execution:
	<TaskInstance: northwin_meltano_pipeline.extract_from_csv_load_csv manual__2025-01-27T23:45:09.276862+00:00 [scheduled]>
	<TaskInstance: northwin_meltano_pipeline.extract_from_postgres_load_csv manual__2025-01-27T23:45:09.276862+00:00 [scheduled]>[0m
[[34m2025-01-27T20:45:10.467-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG northwin_meltano_pipeline has 0/16 running and queued tasks[0m
[[34m2025-01-27T20:45:10.468-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG northwin_meltano_pipeline has 1/16 running and queued tasks[0m
[[34m2025-01-27T20:45:10.468-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: northwin_meltano_pipeline.extract_from_csv_load_csv manual__2025-01-27T23:45:09.276862+00:00 [scheduled]>
	<TaskInstance: northwin_meltano_pipeline.extract_from_postgres_load_csv manual__2025-01-27T23:45:09.276862+00:00 [scheduled]>[0m
[[34m2025-01-27T20:45:10.471-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task extract_from_csv_load_csv because previous state change time has not been saved[0m
[[34m2025-01-27T20:45:10.471-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task extract_from_postgres_load_csv because previous state change time has not been saved[0m
[[34m2025-01-27T20:45:10.473-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='northwin_meltano_pipeline', task_id='extract_from_csv_load_csv', run_id='manual__2025-01-27T23:45:09.276862+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2025-01-27T20:45:10.474-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'northwin_meltano_pipeline', 'extract_from_csv_load_csv', 'manual__2025-01-27T23:45:09.276862+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T20:45:10.474-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='northwin_meltano_pipeline', task_id='extract_from_postgres_load_csv', run_id='manual__2025-01-27T23:45:09.276862+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2025-01-27T20:45:10.475-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'northwin_meltano_pipeline', 'extract_from_postgres_load_csv', 'manual__2025-01-27T23:45:09.276862+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T20:45:10.489-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'northwin_meltano_pipeline', 'extract_from_csv_load_csv', 'manual__2025-01-27T23:45:09.276862+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T20:45:12.027-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/orchestrate/airflow/dags/pipeline_meltano.py[0m
Changing /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/.meltano/utilities/airflow/logs/dag_id=northwin_meltano_pipeline/run_id=manual__2025-01-27T23:45:09.276862+00:00/task_id=extract_from_csv_load_csv permission to 509
[[34m2025-01-27T20:45:12.216-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: northwin_meltano_pipeline.extract_from_csv_load_csv manual__2025-01-27T23:45:09.276862+00:00 [queued]> on host STEFANO-NOTE.[0m
[[34m2025-01-27T20:45:17.444-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'northwin_meltano_pipeline', 'extract_from_postgres_load_csv', 'manual__2025-01-27T23:45:09.276862+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T20:45:19.250-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/orchestrate/airflow/dags/pipeline_meltano.py[0m
Changing /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/.meltano/utilities/airflow/logs/dag_id=northwin_meltano_pipeline/run_id=manual__2025-01-27T23:45:09.276862+00:00/task_id=extract_from_postgres_load_csv permission to 509
[[34m2025-01-27T20:45:19.475-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: northwin_meltano_pipeline.extract_from_postgres_load_csv manual__2025-01-27T23:45:09.276862+00:00 [queued]> on host STEFANO-NOTE.[0m
[[34m2025-01-27T20:45:26.319-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='northwin_meltano_pipeline', task_id='extract_from_csv_load_csv', run_id='manual__2025-01-27T23:45:09.276862+00:00', try_number=1, map_index=-1)[0m
[[34m2025-01-27T20:45:26.320-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='northwin_meltano_pipeline', task_id='extract_from_postgres_load_csv', run_id='manual__2025-01-27T23:45:09.276862+00:00', try_number=1, map_index=-1)[0m
[[34m2025-01-27T20:45:26.325-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=northwin_meltano_pipeline, task_id=extract_from_csv_load_csv, run_id=manual__2025-01-27T23:45:09.276862+00:00, map_index=-1, run_start_date=2025-01-27 23:45:12.296933+00:00, run_end_date=2025-01-27 23:45:16.712336+00:00, run_duration=4.415403, state=up_for_retry, executor_state=success, try_number=1, max_tries=3, job_id=25, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-01-27 23:45:10.469875+00:00, queued_by_job_id=5, pid=21989[0m
[[34m2025-01-27T20:45:26.325-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=northwin_meltano_pipeline, task_id=extract_from_postgres_load_csv, run_id=manual__2025-01-27T23:45:09.276862+00:00, map_index=-1, run_start_date=2025-01-27 23:45:19.568366+00:00, run_end_date=2025-01-27 23:45:25.833560+00:00, run_duration=6.265194, state=success, executor_state=success, try_number=1, max_tries=3, job_id=26, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-01-27 23:45:10.469875+00:00, queued_by_job_id=5, pid=22010[0m
[[34m2025-01-27T20:46:07.887-0300[0m] {[34mscheduler_job_runner.py:[0m1619} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2025-01-27T20:48:16.818-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: northwin_meltano_pipeline.extract_from_csv_load_csv manual__2025-01-27T23:45:09.276862+00:00 [scheduled]>[0m
[[34m2025-01-27T20:48:16.819-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG northwin_meltano_pipeline has 0/16 running and queued tasks[0m
[[34m2025-01-27T20:48:16.819-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: northwin_meltano_pipeline.extract_from_csv_load_csv manual__2025-01-27T23:45:09.276862+00:00 [scheduled]>[0m
[[34m2025-01-27T20:48:16.822-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='northwin_meltano_pipeline', task_id='extract_from_csv_load_csv', run_id='manual__2025-01-27T23:45:09.276862+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2025-01-27T20:48:16.822-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'northwin_meltano_pipeline', 'extract_from_csv_load_csv', 'manual__2025-01-27T23:45:09.276862+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T20:48:16.834-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'northwin_meltano_pipeline', 'extract_from_csv_load_csv', 'manual__2025-01-27T23:45:09.276862+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T20:48:18.911-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/orchestrate/airflow/dags/pipeline_meltano.py[0m
[[34m2025-01-27T20:48:19.105-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: northwin_meltano_pipeline.extract_from_csv_load_csv manual__2025-01-27T23:45:09.276862+00:00 [queued]> on host STEFANO-NOTE.[0m
[[34m2025-01-27T20:48:24.354-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='northwin_meltano_pipeline', task_id='extract_from_csv_load_csv', run_id='manual__2025-01-27T23:45:09.276862+00:00', try_number=2, map_index=-1)[0m
[[34m2025-01-27T20:48:24.360-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=northwin_meltano_pipeline, task_id=extract_from_csv_load_csv, run_id=manual__2025-01-27T23:45:09.276862+00:00, map_index=-1, run_start_date=2025-01-27 23:48:19.208495+00:00, run_end_date=2025-01-27 23:48:23.832617+00:00, run_duration=4.624122, state=up_for_retry, executor_state=success, try_number=2, max_tries=3, job_id=27, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-01-27 23:48:16.820848+00:00, queued_by_job_id=5, pid=22534[0m
[[34m2025-01-27T20:51:06.030-0300[0m] {[34mscheduler_job_runner.py:[0m1619} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2025-01-27T20:51:24.534-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: northwin_meltano_pipeline.extract_from_csv_load_csv manual__2025-01-27T23:45:09.276862+00:00 [scheduled]>[0m
[[34m2025-01-27T20:51:24.535-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG northwin_meltano_pipeline has 0/16 running and queued tasks[0m
[[34m2025-01-27T20:51:24.536-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: northwin_meltano_pipeline.extract_from_csv_load_csv manual__2025-01-27T23:45:09.276862+00:00 [scheduled]>[0m
[[34m2025-01-27T20:51:24.541-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='northwin_meltano_pipeline', task_id='extract_from_csv_load_csv', run_id='manual__2025-01-27T23:45:09.276862+00:00', try_number=3, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2025-01-27T20:51:24.543-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'northwin_meltano_pipeline', 'extract_from_csv_load_csv', 'manual__2025-01-27T23:45:09.276862+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T20:51:24.558-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'northwin_meltano_pipeline', 'extract_from_csv_load_csv', 'manual__2025-01-27T23:45:09.276862+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T20:51:26.411-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/orchestrate/airflow/dags/pipeline_meltano.py[0m
[[34m2025-01-27T20:51:26.656-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: northwin_meltano_pipeline.extract_from_csv_load_csv manual__2025-01-27T23:45:09.276862+00:00 [queued]> on host STEFANO-NOTE.[0m
[[34m2025-01-27T20:51:32.110-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='northwin_meltano_pipeline', task_id='extract_from_csv_load_csv', run_id='manual__2025-01-27T23:45:09.276862+00:00', try_number=3, map_index=-1)[0m
[[34m2025-01-27T20:51:32.117-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=northwin_meltano_pipeline, task_id=extract_from_csv_load_csv, run_id=manual__2025-01-27T23:45:09.276862+00:00, map_index=-1, run_start_date=2025-01-27 23:51:26.725110+00:00, run_end_date=2025-01-27 23:51:31.372477+00:00, run_duration=4.647367, state=up_for_retry, executor_state=success, try_number=3, max_tries=3, job_id=28, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-01-27 23:51:24.538386+00:00, queued_by_job_id=5, pid=23077[0m
[[34m2025-01-27T20:54:32.518-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: northwin_meltano_pipeline.extract_from_csv_load_csv manual__2025-01-27T23:45:09.276862+00:00 [scheduled]>[0m
[[34m2025-01-27T20:54:32.518-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG northwin_meltano_pipeline has 0/16 running and queued tasks[0m
[[34m2025-01-27T20:54:32.518-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: northwin_meltano_pipeline.extract_from_csv_load_csv manual__2025-01-27T23:45:09.276862+00:00 [scheduled]>[0m
[[34m2025-01-27T20:54:32.521-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='northwin_meltano_pipeline', task_id='extract_from_csv_load_csv', run_id='manual__2025-01-27T23:45:09.276862+00:00', try_number=4, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2025-01-27T20:54:32.521-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'northwin_meltano_pipeline', 'extract_from_csv_load_csv', 'manual__2025-01-27T23:45:09.276862+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T20:54:32.532-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'northwin_meltano_pipeline', 'extract_from_csv_load_csv', 'manual__2025-01-27T23:45:09.276862+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T20:54:34.307-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/orchestrate/airflow/dags/pipeline_meltano.py[0m
[[34m2025-01-27T20:54:34.500-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: northwin_meltano_pipeline.extract_from_csv_load_csv manual__2025-01-27T23:45:09.276862+00:00 [queued]> on host STEFANO-NOTE.[0m
[[34m2025-01-27T20:54:40.575-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='northwin_meltano_pipeline', task_id='extract_from_csv_load_csv', run_id='manual__2025-01-27T23:45:09.276862+00:00', try_number=4, map_index=-1)[0m
[[34m2025-01-27T20:54:40.581-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=northwin_meltano_pipeline, task_id=extract_from_csv_load_csv, run_id=manual__2025-01-27T23:45:09.276862+00:00, map_index=-1, run_start_date=2025-01-27 23:54:34.621626+00:00, run_end_date=2025-01-27 23:54:39.766471+00:00, run_duration=5.144845, state=failed, executor_state=success, try_number=4, max_tries=3, job_id=29, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-01-27 23:54:32.519626+00:00, queued_by_job_id=5, pid=23741[0m
[[34m2025-01-27T20:54:40.660-0300[0m] {[34mdagrun.py:[0m711} ERROR[0m - Marking run <DagRun northwin_meltano_pipeline @ 2025-01-27 23:45:09.276862+00:00: manual__2025-01-27T23:45:09.276862+00:00, state:running, queued_at: 2025-01-27 23:45:09.294544+00:00. externally triggered: True> failed[0m
[[34m2025-01-27T20:54:40.661-0300[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=northwin_meltano_pipeline, execution_date=2025-01-27 23:45:09.276862+00:00, run_id=manual__2025-01-27T23:45:09.276862+00:00, run_start_date=2025-01-27 23:45:10.415068+00:00, run_end_date=2025-01-27 23:54:40.661174+00:00, run_duration=570.246106, state=failed, external_trigger=True, run_type=manual, data_interval_start=2025-01-26 00:00:00+00:00, data_interval_end=2025-01-27 00:00:00+00:00, dag_hash=b2225949f66fd87f5b12f0045741e646[0m
[[34m2025-01-27T20:55:52.192-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 2 tasks up for execution:
	<TaskInstance: northwind_meltano_pipeline.extract_from_csv_load_csv manual__2025-01-27T23:55:50.481784+00:00 [scheduled]>
	<TaskInstance: northwind_meltano_pipeline.extract_from_postgres_load_csv manual__2025-01-27T23:55:50.481784+00:00 [scheduled]>[0m
[[34m2025-01-27T20:55:52.192-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG northwind_meltano_pipeline has 0/16 running and queued tasks[0m
[[34m2025-01-27T20:55:52.193-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG northwind_meltano_pipeline has 1/16 running and queued tasks[0m
[[34m2025-01-27T20:55:52.193-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: northwind_meltano_pipeline.extract_from_csv_load_csv manual__2025-01-27T23:55:50.481784+00:00 [scheduled]>
	<TaskInstance: northwind_meltano_pipeline.extract_from_postgres_load_csv manual__2025-01-27T23:55:50.481784+00:00 [scheduled]>[0m
[[34m2025-01-27T20:55:52.195-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task extract_from_csv_load_csv because previous state change time has not been saved[0m
[[34m2025-01-27T20:55:52.195-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task extract_from_postgres_load_csv because previous state change time has not been saved[0m
[[34m2025-01-27T20:55:52.196-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='northwind_meltano_pipeline', task_id='extract_from_csv_load_csv', run_id='manual__2025-01-27T23:55:50.481784+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2025-01-27T20:55:52.197-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'northwind_meltano_pipeline', 'extract_from_csv_load_csv', 'manual__2025-01-27T23:55:50.481784+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T20:55:52.198-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='northwind_meltano_pipeline', task_id='extract_from_postgres_load_csv', run_id='manual__2025-01-27T23:55:50.481784+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2025-01-27T20:55:52.199-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'northwind_meltano_pipeline', 'extract_from_postgres_load_csv', 'manual__2025-01-27T23:55:50.481784+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T20:55:50.568-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'northwind_meltano_pipeline', 'extract_from_csv_load_csv', 'manual__2025-01-27T23:55:50.481784+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T20:55:52.533-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/orchestrate/airflow/dags/pipeline_meltano.py[0m
Changing /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/.meltano/utilities/airflow/logs/dag_id=northwind_meltano_pipeline/run_id=manual__2025-01-27T23:55:50.481784+00:00/task_id=extract_from_csv_load_csv permission to 509
[[34m2025-01-27T20:55:52.758-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: northwind_meltano_pipeline.extract_from_csv_load_csv manual__2025-01-27T23:55:50.481784+00:00 [queued]> on host STEFANO-NOTE.[0m
[[34m2025-01-27T20:56:00.600-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'northwind_meltano_pipeline', 'extract_from_postgres_load_csv', 'manual__2025-01-27T23:55:50.481784+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T20:56:01.943-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/orchestrate/airflow/dags/pipeline_meltano.py[0m
Changing /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/.meltano/utilities/airflow/logs/dag_id=northwind_meltano_pipeline/run_id=manual__2025-01-27T23:55:50.481784+00:00/task_id=extract_from_postgres_load_csv permission to 509
[[34m2025-01-27T20:56:02.103-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: northwind_meltano_pipeline.extract_from_postgres_load_csv manual__2025-01-27T23:55:50.481784+00:00 [queued]> on host STEFANO-NOTE.[0m
[[34m2025-01-27T20:56:08.672-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='northwind_meltano_pipeline', task_id='extract_from_csv_load_csv', run_id='manual__2025-01-27T23:55:50.481784+00:00', try_number=1, map_index=-1)[0m
[[34m2025-01-27T20:56:08.672-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='northwind_meltano_pipeline', task_id='extract_from_postgres_load_csv', run_id='manual__2025-01-27T23:55:50.481784+00:00', try_number=1, map_index=-1)[0m
[[34m2025-01-27T20:56:08.677-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=northwind_meltano_pipeline, task_id=extract_from_csv_load_csv, run_id=manual__2025-01-27T23:55:50.481784+00:00, map_index=-1, run_start_date=2025-01-27 23:55:52.853895+00:00, run_end_date=2025-01-27 23:56:00.053478+00:00, run_duration=7.199583, state=up_for_retry, executor_state=success, try_number=1, max_tries=3, job_id=30, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-01-27 23:55:52.193890+00:00, queued_by_job_id=5, pid=24046[0m
[[34m2025-01-27T20:56:08.678-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=northwind_meltano_pipeline, task_id=extract_from_postgres_load_csv, run_id=manual__2025-01-27T23:55:50.481784+00:00, map_index=-1, run_start_date=2025-01-27 23:56:02.178984+00:00, run_end_date=2025-01-27 23:56:08.145798+00:00, run_duration=5.966814, state=success, executor_state=success, try_number=1, max_tries=3, job_id=31, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-01-27 23:55:52.193890+00:00, queued_by_job_id=5, pid=24086[0m
[[34m2025-01-27T20:56:08.714-0300[0m] {[34mscheduler_job_runner.py:[0m1619} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[2025-01-27T20:57:08.908-0300] {manager.py:523} INFO - DAG northwin_meltano_pipeline is missing and will be deactivated.
[2025-01-27T20:57:08.911-0300] {manager.py:535} INFO - Deactivated 1 DAGs which are no longer present in file.
[2025-01-27T20:57:08.943-0300] {manager.py:539} INFO - Deleted DAG northwin_meltano_pipeline in serialized_dag table
[[34m2025-01-27T20:57:56.502-0300[0m] {[34mdagrun.py:[0m711} ERROR[0m - Marking run <DagRun northwind_meltano_pipeline @ 2025-01-27 23:55:50.481784+00:00: manual__2025-01-27T23:55:50.481784+00:00, state:running, queued_at: 2025-01-27 23:55:50.492466+00:00. externally triggered: True> failed[0m
[[34m2025-01-27T20:57:56.503-0300[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=northwind_meltano_pipeline, execution_date=2025-01-27 23:55:50.481784+00:00, run_id=manual__2025-01-27T23:55:50.481784+00:00, run_start_date=2025-01-27 23:55:52.124860+00:00, run_end_date=2025-01-27 23:57:56.503327+00:00, run_duration=124.378467, state=failed, external_trigger=True, run_type=manual, data_interval_start=2025-01-26 00:00:00+00:00, data_interval_end=2025-01-27 00:00:00+00:00, dag_hash=a3411272e58739a0b4b59ed0e905d32a[0m
[[34m2025-01-27T20:58:20.543-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 2 tasks up for execution:
	<TaskInstance: northwind_meltano_pipeline.extract_from_csv_load_csv manual__2025-01-27T23:58:19.444880+00:00 [scheduled]>
	<TaskInstance: northwind_meltano_pipeline.extract_from_postgres_load_csv manual__2025-01-27T23:58:19.444880+00:00 [scheduled]>[0m
[[34m2025-01-27T20:58:20.544-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG northwind_meltano_pipeline has 0/16 running and queued tasks[0m
[[34m2025-01-27T20:58:20.544-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG northwind_meltano_pipeline has 1/16 running and queued tasks[0m
[[34m2025-01-27T20:58:20.545-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: northwind_meltano_pipeline.extract_from_csv_load_csv manual__2025-01-27T23:58:19.444880+00:00 [scheduled]>
	<TaskInstance: northwind_meltano_pipeline.extract_from_postgres_load_csv manual__2025-01-27T23:58:19.444880+00:00 [scheduled]>[0m
[[34m2025-01-27T20:58:20.547-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task extract_from_csv_load_csv because previous state change time has not been saved[0m
[[34m2025-01-27T20:58:20.547-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task extract_from_postgres_load_csv because previous state change time has not been saved[0m
[[34m2025-01-27T20:58:20.548-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='northwind_meltano_pipeline', task_id='extract_from_csv_load_csv', run_id='manual__2025-01-27T23:58:19.444880+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2025-01-27T20:58:20.549-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'northwind_meltano_pipeline', 'extract_from_csv_load_csv', 'manual__2025-01-27T23:58:19.444880+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T20:58:20.549-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='northwind_meltano_pipeline', task_id='extract_from_postgres_load_csv', run_id='manual__2025-01-27T23:58:19.444880+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2025-01-27T20:58:20.550-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'northwind_meltano_pipeline', 'extract_from_postgres_load_csv', 'manual__2025-01-27T23:58:19.444880+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T20:58:20.566-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'northwind_meltano_pipeline', 'extract_from_csv_load_csv', 'manual__2025-01-27T23:58:19.444880+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T20:58:22.566-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/orchestrate/airflow/dags/pipeline_meltano.py[0m
Changing /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/.meltano/utilities/airflow/logs/dag_id=northwind_meltano_pipeline/run_id=manual__2025-01-27T23:58:19.444880+00:00/task_id=extract_from_csv_load_csv permission to 509
[[34m2025-01-27T20:58:22.860-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: northwind_meltano_pipeline.extract_from_csv_load_csv manual__2025-01-27T23:58:19.444880+00:00 [queued]> on host STEFANO-NOTE.[0m
[[34m2025-01-27T20:58:28.811-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'northwind_meltano_pipeline', 'extract_from_postgres_load_csv', 'manual__2025-01-27T23:58:19.444880+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T20:58:30.541-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/orchestrate/airflow/dags/pipeline_meltano.py[0m
Changing /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/.meltano/utilities/airflow/logs/dag_id=northwind_meltano_pipeline/run_id=manual__2025-01-27T23:58:19.444880+00:00/task_id=extract_from_postgres_load_csv permission to 509
[[34m2025-01-27T20:58:30.725-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: northwind_meltano_pipeline.extract_from_postgres_load_csv manual__2025-01-27T23:58:19.444880+00:00 [queued]> on host STEFANO-NOTE.[0m
[[34m2025-01-27T20:58:37.991-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='northwind_meltano_pipeline', task_id='extract_from_csv_load_csv', run_id='manual__2025-01-27T23:58:19.444880+00:00', try_number=1, map_index=-1)[0m
[[34m2025-01-27T20:58:37.991-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='northwind_meltano_pipeline', task_id='extract_from_postgres_load_csv', run_id='manual__2025-01-27T23:58:19.444880+00:00', try_number=1, map_index=-1)[0m
[[34m2025-01-27T20:58:37.998-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=northwind_meltano_pipeline, task_id=extract_from_csv_load_csv, run_id=manual__2025-01-27T23:58:19.444880+00:00, map_index=-1, run_start_date=2025-01-27 23:58:22.944171+00:00, run_end_date=2025-01-27 23:58:28.138819+00:00, run_duration=5.194648, state=success, executor_state=success, try_number=1, max_tries=3, job_id=32, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-01-27 23:58:20.545707+00:00, queued_by_job_id=5, pid=24494[0m
[[34m2025-01-27T20:58:37.998-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=northwind_meltano_pipeline, task_id=extract_from_postgres_load_csv, run_id=manual__2025-01-27T23:58:19.444880+00:00, map_index=-1, run_start_date=2025-01-27 23:58:30.835880+00:00, run_end_date=2025-01-27 23:58:37.268491+00:00, run_duration=6.432611, state=success, executor_state=success, try_number=1, max_tries=3, job_id=33, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-01-27 23:58:20.545707+00:00, queued_by_job_id=5, pid=24528[0m
[[34m2025-01-27T20:58:40.932-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: northwind_meltano_pipeline.extract_from_csv_load_postgres manual__2025-01-27T23:58:19.444880+00:00 [scheduled]>[0m
[[34m2025-01-27T20:58:40.932-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG northwind_meltano_pipeline has 0/16 running and queued tasks[0m
[[34m2025-01-27T20:58:40.933-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: northwind_meltano_pipeline.extract_from_csv_load_postgres manual__2025-01-27T23:58:19.444880+00:00 [scheduled]>[0m
[[34m2025-01-27T20:58:40.935-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task extract_from_csv_load_postgres because previous state change time has not been saved[0m
[[34m2025-01-27T20:58:40.936-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='northwind_meltano_pipeline', task_id='extract_from_csv_load_postgres', run_id='manual__2025-01-27T23:58:19.444880+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2025-01-27T20:58:40.936-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'northwind_meltano_pipeline', 'extract_from_csv_load_postgres', 'manual__2025-01-27T23:58:19.444880+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T20:58:40.956-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'northwind_meltano_pipeline', 'extract_from_csv_load_postgres', 'manual__2025-01-27T23:58:19.444880+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T20:58:42.796-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/orchestrate/airflow/dags/pipeline_meltano.py[0m
Changing /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/.meltano/utilities/airflow/logs/dag_id=northwind_meltano_pipeline/run_id=manual__2025-01-27T23:58:19.444880+00:00/task_id=extract_from_csv_load_postgres permission to 509
[[34m2025-01-27T20:58:42.984-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: northwind_meltano_pipeline.extract_from_csv_load_postgres manual__2025-01-27T23:58:19.444880+00:00 [queued]> on host STEFANO-NOTE.[0m
[[34m2025-01-27T20:58:51.883-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='northwind_meltano_pipeline', task_id='extract_from_csv_load_postgres', run_id='manual__2025-01-27T23:58:19.444880+00:00', try_number=1, map_index=-1)[0m
[[34m2025-01-27T20:58:51.889-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=northwind_meltano_pipeline, task_id=extract_from_csv_load_postgres, run_id=manual__2025-01-27T23:58:19.444880+00:00, map_index=-1, run_start_date=2025-01-27 23:58:43.080672+00:00, run_end_date=2025-01-27 23:58:51.304326+00:00, run_duration=8.223654, state=success, executor_state=success, try_number=1, max_tries=3, job_id=34, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2025-01-27 23:58:40.934035+00:00, queued_by_job_id=5, pid=24583[0m
[[34m2025-01-27T20:58:52.175-0300[0m] {[34mdagrun.py:[0m732} INFO[0m - Marking run <DagRun northwind_meltano_pipeline @ 2025-01-27 23:58:19.444880+00:00: manual__2025-01-27T23:58:19.444880+00:00, state:running, queued_at: 2025-01-27 23:58:19.480946+00:00. externally triggered: True> successful[0m
[[34m2025-01-27T20:58:52.176-0300[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=northwind_meltano_pipeline, execution_date=2025-01-27 23:58:19.444880+00:00, run_id=manual__2025-01-27T23:58:19.444880+00:00, run_start_date=2025-01-27 23:58:20.492593+00:00, run_end_date=2025-01-27 23:58:52.176278+00:00, run_duration=31.683685, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-01-26 00:00:00+00:00, data_interval_end=2025-01-27 00:00:00+00:00, dag_hash=a3411272e58739a0b4b59ed0e905d32a[0m
[[34m2025-01-27T21:00:01.487-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for northwind_meltano_pipeline to 2025-01-28 00:00:00+00:00, run_after=2025-01-29 00:00:00+00:00[0m
[[34m2025-01-27T21:00:01.597-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 2 tasks up for execution:
	<TaskInstance: northwind_meltano_pipeline.extract_from_csv_load_csv scheduled__2025-01-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: northwind_meltano_pipeline.extract_from_postgres_load_csv scheduled__2025-01-27T00:00:00+00:00 [scheduled]>[0m
[[34m2025-01-27T21:00:01.597-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG northwind_meltano_pipeline has 0/16 running and queued tasks[0m
[[34m2025-01-27T21:00:01.597-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG northwind_meltano_pipeline has 1/16 running and queued tasks[0m
[[34m2025-01-27T21:00:01.598-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: northwind_meltano_pipeline.extract_from_csv_load_csv scheduled__2025-01-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: northwind_meltano_pipeline.extract_from_postgres_load_csv scheduled__2025-01-27T00:00:00+00:00 [scheduled]>[0m
[[34m2025-01-27T21:00:01.600-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task extract_from_csv_load_csv because previous state change time has not been saved[0m
[[34m2025-01-27T21:00:01.600-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task extract_from_postgres_load_csv because previous state change time has not been saved[0m
[[34m2025-01-27T21:00:01.601-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='northwind_meltano_pipeline', task_id='extract_from_csv_load_csv', run_id='scheduled__2025-01-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2025-01-27T21:00:01.601-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'northwind_meltano_pipeline', 'extract_from_csv_load_csv', 'scheduled__2025-01-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T21:00:01.602-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='northwind_meltano_pipeline', task_id='extract_from_postgres_load_csv', run_id='scheduled__2025-01-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2025-01-27T21:00:01.602-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'northwind_meltano_pipeline', 'extract_from_postgres_load_csv', 'scheduled__2025-01-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T21:00:01.614-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'northwind_meltano_pipeline', 'extract_from_csv_load_csv', 'scheduled__2025-01-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T21:00:03.612-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/orchestrate/airflow/dags/pipeline_meltano.py[0m
Changing /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/.meltano/utilities/airflow/logs/dag_id=northwind_meltano_pipeline/run_id=scheduled__2025-01-27T00:00:00+00:00/task_id=extract_from_csv_load_csv permission to 509
[[34m2025-01-27T21:00:03.837-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: northwind_meltano_pipeline.extract_from_csv_load_csv scheduled__2025-01-27T00:00:00+00:00 [queued]> on host STEFANO-NOTE.[0m
[[34m2025-01-27T21:00:09.451-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'northwind_meltano_pipeline', 'extract_from_postgres_load_csv', 'scheduled__2025-01-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T21:00:10.834-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/orchestrate/airflow/dags/pipeline_meltano.py[0m
Changing /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/.meltano/utilities/airflow/logs/dag_id=northwind_meltano_pipeline/run_id=scheduled__2025-01-27T00:00:00+00:00/task_id=extract_from_postgres_load_csv permission to 509
[[34m2025-01-27T21:00:10.977-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: northwind_meltano_pipeline.extract_from_postgres_load_csv scheduled__2025-01-27T00:00:00+00:00 [queued]> on host STEFANO-NOTE.[0m
[[34m2025-01-27T21:00:17.398-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='northwind_meltano_pipeline', task_id='extract_from_csv_load_csv', run_id='scheduled__2025-01-27T00:00:00+00:00', try_number=1, map_index=-1)[0m
[[34m2025-01-27T21:00:17.399-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='northwind_meltano_pipeline', task_id='extract_from_postgres_load_csv', run_id='scheduled__2025-01-27T00:00:00+00:00', try_number=1, map_index=-1)[0m
[[34m2025-01-27T21:00:17.404-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=northwind_meltano_pipeline, task_id=extract_from_csv_load_csv, run_id=scheduled__2025-01-27T00:00:00+00:00, map_index=-1, run_start_date=2025-01-28 00:00:03.907934+00:00, run_end_date=2025-01-28 00:00:08.954433+00:00, run_duration=5.046499, state=success, executor_state=success, try_number=1, max_tries=3, job_id=35, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-01-28 00:00:01.598663+00:00, queued_by_job_id=5, pid=24865[0m
[[34m2025-01-27T21:00:17.405-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=northwind_meltano_pipeline, task_id=extract_from_postgres_load_csv, run_id=scheduled__2025-01-27T00:00:00+00:00, map_index=-1, run_start_date=2025-01-28 00:00:11.061268+00:00, run_end_date=2025-01-28 00:00:16.874436+00:00, run_duration=5.813168, state=success, executor_state=success, try_number=1, max_tries=3, job_id=36, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-01-28 00:00:01.598663+00:00, queued_by_job_id=5, pid=24906[0m
[[34m2025-01-27T21:00:20.149-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: northwind_meltano_pipeline.extract_from_csv_load_postgres scheduled__2025-01-27T00:00:00+00:00 [scheduled]>[0m
[[34m2025-01-27T21:00:20.150-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG northwind_meltano_pipeline has 0/16 running and queued tasks[0m
[[34m2025-01-27T21:00:20.151-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: northwind_meltano_pipeline.extract_from_csv_load_postgres scheduled__2025-01-27T00:00:00+00:00 [scheduled]>[0m
[[34m2025-01-27T21:00:20.155-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task extract_from_csv_load_postgres because previous state change time has not been saved[0m
[[34m2025-01-27T21:00:20.157-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='northwind_meltano_pipeline', task_id='extract_from_csv_load_postgres', run_id='scheduled__2025-01-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2025-01-27T21:00:20.158-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'northwind_meltano_pipeline', 'extract_from_csv_load_postgres', 'scheduled__2025-01-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T21:00:20.189-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'northwind_meltano_pipeline', 'extract_from_csv_load_postgres', 'scheduled__2025-01-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/pipeline_meltano.py'][0m
[[34m2025-01-27T21:00:21.991-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/orchestrate/airflow/dags/pipeline_meltano.py[0m
Changing /home/stefanovivas/challenge-indicum-2/indicium-code-challenge/my-meltano-project/.meltano/utilities/airflow/logs/dag_id=northwind_meltano_pipeline/run_id=scheduled__2025-01-27T00:00:00+00:00/task_id=extract_from_csv_load_postgres permission to 509
[[34m2025-01-27T21:00:22.196-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: northwind_meltano_pipeline.extract_from_csv_load_postgres scheduled__2025-01-27T00:00:00+00:00 [queued]> on host STEFANO-NOTE.[0m
[[34m2025-01-27T21:00:31.190-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='northwind_meltano_pipeline', task_id='extract_from_csv_load_postgres', run_id='scheduled__2025-01-27T00:00:00+00:00', try_number=1, map_index=-1)[0m
[[34m2025-01-27T21:00:31.195-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=northwind_meltano_pipeline, task_id=extract_from_csv_load_postgres, run_id=scheduled__2025-01-27T00:00:00+00:00, map_index=-1, run_start_date=2025-01-28 00:00:22.291469+00:00, run_end_date=2025-01-28 00:00:30.384265+00:00, run_duration=8.092796, state=success, executor_state=success, try_number=1, max_tries=3, job_id=37, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2025-01-28 00:00:20.152190+00:00, queued_by_job_id=5, pid=24962[0m
[[34m2025-01-27T21:00:31.499-0300[0m] {[34mdagrun.py:[0m732} INFO[0m - Marking run <DagRun northwind_meltano_pipeline @ 2025-01-27 00:00:00+00:00: scheduled__2025-01-27T00:00:00+00:00, state:running, queued_at: 2025-01-28 00:00:01.480789+00:00. externally triggered: False> successful[0m
[[34m2025-01-27T21:00:31.500-0300[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=northwind_meltano_pipeline, execution_date=2025-01-27 00:00:00+00:00, run_id=scheduled__2025-01-27T00:00:00+00:00, run_start_date=2025-01-28 00:00:01.535251+00:00, run_end_date=2025-01-28 00:00:31.500090+00:00, run_duration=29.964839, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-01-27 00:00:00+00:00, data_interval_end=2025-01-28 00:00:00+00:00, dag_hash=a3411272e58739a0b4b59ed0e905d32a[0m
[[34m2025-01-27T21:00:31.505-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for northwind_meltano_pipeline to 2025-01-28 00:00:00+00:00, run_after=2025-01-29 00:00:00+00:00[0m
[[34m2025-01-27T21:01:08.762-0300[0m] {[34mscheduler_job_runner.py:[0m1619} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2025-01-27T21:06:06.845-0300[0m] {[34mscheduler_job_runner.py:[0m1619} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2025-01-27T21:11:06.889-0300[0m] {[34mscheduler_job_runner.py:[0m1619} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2025-01-27T21:16:04.956-0300[0m] {[34mscheduler_job_runner.py:[0m1619} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2025-01-27T21:21:05.077-0300[0m] {[34mscheduler_job_runner.py:[0m1619} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2025-01-27T21:26:05.130-0300[0m] {[34mscheduler_job_runner.py:[0m1619} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
